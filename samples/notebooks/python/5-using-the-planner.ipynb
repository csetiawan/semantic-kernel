{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a80181",
   "metadata": {},
   "source": [
    "# ⚠️ PLANNER NOT YET IMPLEMENTED IN PYTHON\n",
    "\n",
    "# Introduction to the Planner\n",
    "\n",
    "The Planner is one of the fundamental concepts of the Semantic Kernel. It makes use of the collection of skills that have been registered to the kernel and using AI, will formulate a plan to execute a given ask.\n",
    "\n",
    "Read more about it [here](https://aka.ms/sk/concepts/planner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e59885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init import *\n",
    "import semantic_kernel as sk\n",
    "\n",
    "kernel = sk.KernelBuilder.create_kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "model = \"text-davinci-002\"\n",
    "\n",
    "# Configure AI backend used by the kernel\n",
    "if (useAzureOpenAI):\n",
    "    api_key, endpoint = azure_openai_settings_from_dot_env()\n",
    "    kernel.config.add_azure_openai_completion_backend(\"davinci\", model, endpoint, api_key)\n",
    "else:\n",
    "    api_key, org_id = openai_settings_from_dot_env()\n",
    "    kernel.config.add_openai_completion_backend(\"davinci\", model, api_key, org_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c885ced",
   "metadata": {},
   "source": [
    "### Setting Up the Planner\n",
    "The planner is located in the Semantic Kernel's CoreSkills and requires Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_skills import PlannerSkill\n",
    "from semantic_kernel.kernel_extensions.import_semantic_skill_from_directory import import_semantic_skill_from_directory\n",
    "\n",
    "# Load native skill into the kernel registry, sharing its functions with prompt templates\n",
    "planner = kernel.import_skill(PlannerSkill(kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147587de",
   "metadata": {},
   "source": [
    "You can see that the Planner took my ask and converted it into an XML-based plan detailing\n",
    "how the AI would go about solving this task, making use of the skills that the Kernel has available to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d86739",
   "metadata": {},
   "source": [
    "### Providing skills to the planner\n",
    "The planner needs to know what skills are available to it. Here we'll give it access to the `SummarizeSkill` and `WriterSkill` we have defined on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_directory = \"../../skills\"\n",
    "skill = import_semantic_skill_from_directory(kernel, skills_directory, \"SummarizeSkill\")\n",
    "skill = import_semantic_skill_from_directory(kernel, skills_directory, \"WriterSkill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deff5675",
   "metadata": {},
   "source": [
    "Define your ASK. What do you want the Kernel to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d537981",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"Tomorrow is Valentine's day. I need to come up with a few date ideas and e-mail them to my significant other.\";\n",
    "originalPlan = await kernel.run_on_str_async(ask, planner[\"CreatePlan\"])\n",
    "\n",
    "print(\"Original plan:\\n\");\n",
    "print(originalPlan.variales.to_plan().plan_string);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318dc72",
   "metadata": {},
   "source": [
    "As you can see in the above plan, the AI has determined which functions to call \n",
    "in order to fulfill the user ask. The output of each step of the plan gets set as `setContextVariable` which makes it available as `input` to the next skill. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c88a7",
   "metadata": {},
   "source": [
    "Let's also define an inline skill and have it be available to the Planner.\n",
    "Be sure to give it a function name and skill name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Rewrite the above in the style of Shakespeare.\n",
    "\"\"\"\n",
    "shakespeareFunction = kernel.CreateSemanticFunction(sk_prompt, \"shakespeare\", \"ShakespeareSkill\", max_tokens: 2000, temperature: 0.2, top_p: 0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305743f5",
   "metadata": {},
   "source": [
    "Let's update our ask using this new skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd23ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"Tomorrow is Valentine's day. I need to come up with a few date ideas.\n",
    " She likes Shakespeare so write using his style. E-mail these ideas to my significant other\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0549fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_plan = await kernel.run_on_str_async(ask, planner[\"CreatePlan\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe479d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Updated plan:\\n\");\n",
    "print(new_plan.variales.to_plan().plan_string);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6ac56",
   "metadata": {},
   "source": [
    "### Executing the plan\n",
    "\n",
    "Now that we have a plan, let's try to execute it! The Planner has a skill called `ExecutePlan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_results = new_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "maxSteps = 10\n",
    "while (not execution_results.variales.to_plan().is_complete and step < maxSteps):\n",
    "    results = await kernel.run_on_str_async(execution_results.variables, planner[\"ExecutePlan\"])\n",
    "    if (results.variabes.to_plan().is_successful):\n",
    "        print(\"Step {step} - Execution results:\\n\")\n",
    "        print(results.variables.to_plan().plan_string)\n",
    "\n",
    "        if (results.variables.to_plan().is_complete):\n",
    "            print(\"Step {step} - COMPLETE!\")\n",
    "            print(results.variables.to_plan().result)\n",
    "            break\n",
    "    else:\n",
    "        print(\"Step {step} - Execution failed:\")\n",
    "        print(results.variables.to_plan().result)\n",
    "        break\n",
    "    \n",
    "    execution_results = results\n",
    "    step += 1\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
