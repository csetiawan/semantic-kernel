{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde98ddf",
   "metadata": {},
   "source": [
    "# Creating a basic chat experience with context variables\n",
    "\n",
    "In this example, we show how you can build a simple chat bot by sending and updating context with your requests. \n",
    "\n",
    "We introduce the Context Variables object which in this demo functions similarly as a key-value store that you can use when running the kernel.\n",
    "\n",
    "The context is local (i.e. in your computer's RAM) and not persisted anywhere beyond the life of this Jupyter session.\n",
    "\n",
    "In future examples, we will show how to persist the context on disk so that you can bring it into your applications.  \n",
    "\n",
    "In this chat scenario, as the user talks back and forth with the bot, the context gets populated with the history of the conversation. During each new run of the kernel, the context can provide the AI with its variables' content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68301108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init import *\n",
    "import semantic_kernel as sk\n",
    "\n",
    "kernel = sk.KernelBuilder.create_kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "model = \"text-davinci-003\"\n",
    "\n",
    "# Configure AI backend used by the kernel\n",
    "if (useAzureOpenAI):\n",
    "    api_key, endpoint = azure_openai_settings_from_dot_env()\n",
    "    kernel.config.add_azure_openai_completion_backend(\"davinci\", model, endpoint, api_key, overwrite=True)\n",
    "else:\n",
    "    api_key, org_id = openai_settings_from_dot_env()\n",
    "    kernel.config.add_openai_completion_backend(\"davinci\", model, api_key, org_id, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971783d",
   "metadata": {},
   "source": [
    "Let's define a prompt outlining a dialogue chat bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a05fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "ChatBot can have a conversation with you about any topic.\n",
    "It can give explicit instructions or say 'I don't know' if it does not have an answer.\n",
    "\n",
    "{{$history}}\n",
    "Human: {{$human_input}}\n",
    "ChatBot:\";\n",
    "\"\"\"\n",
    "\n",
    "prompt_config = sk.PromptTemplateConfig.from_completion_parameters(\n",
    "    max_tokens=2000, temperature=0.7, top_p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61716b16",
   "metadata": {},
   "source": [
    "Register your semantic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e4b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = sk.PromptTemplate(sk_prompt, kernel.prompt_template_engine, prompt_config)\n",
    "\n",
    "function_config = sk.SemanticFunctionConfig(prompt_config, prompt_template)\n",
    "chat_function = kernel.register_semantic_function(\"ChatBot\", \"Chat\", function_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a676f",
   "metadata": {},
   "source": [
    "Initialize your context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = sk.ContextVariables()\n",
    "\n",
    "history = \"\"\n",
    "context.set(\"history\", history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce7c497",
   "metadata": {},
   "source": [
    "Chat with the Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec41eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_input = \"Hi, I'm looking for book suggestions\"\n",
    "context.set(\"human_input\", human_input)\n",
    "\n",
    "bot_answer = await kernel.run_on_str_async(context, chat_function)\n",
    "print(bot_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b03748",
   "metadata": {},
   "source": [
    "Update the history with the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history += \"\\nHuman: {human_input}\\nMelody: {bot_answer}\\n\"\n",
    "context.update(history);\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a2eb02",
   "metadata": {},
   "source": [
    "Keep Chatting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59efe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = \"\"\n",
    "async def chat(input_text: str) -> str:\n",
    "    global history\n",
    "    # Save new message in the context variables\n",
    "    context.set(\"human_input\", input_text)\n",
    "\n",
    "    # Process the user message and get an answer\n",
    "    answer = await kernel.run_on_str_async(context, chat_function)\n",
    "\n",
    "    # Append the new interaction to the chat history\n",
    "    history = history + f\"\\nHuman: {input_text}\\nMelody: {answer}\\n\"\n",
    "    context.set(\"history\", history)\n",
    "\n",
    "    # Show the response\n",
    "    print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"I love history and philosophy, I'd like to learn something new about Greece, any suggestion?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be4e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"that sounds interesting, what is it about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"if I read that book, what exactly will I learn about Greece history?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b3a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"could you list some more books I could read about this topic?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
